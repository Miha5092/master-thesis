{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from src.utils.visualization import animate_predictions, animate_results, plot_noise_effects, split_and_save_chunks, plot_real_sensor_partitioning\n",
    "from src.datasets.utils import get_noise, read_real_observation_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.evaluation import *\n",
    "\n",
    "from src.datasets.real_obs_dataset import load_data as load_real_data\n",
    "from src.datasets.vitae_dataset import unscale, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def add_hours(date_str: str, hours: int, date_format: str = \"%Y-%m-%d %H:%M:%S\") -> str:\n",
    "    \"\"\"\n",
    "    Add a number of hours to a given date string.\n",
    "\n",
    "    Args:\n",
    "        date_str (str): Input date string (e.g., \"2025-09-05 13:30:00\").\n",
    "        hours (int): Number of hours to add (can be negative).\n",
    "        date_format (str): Format of the input/output date string.\n",
    "\n",
    "    Returns:\n",
    "        str: New date string after adding the hours.\n",
    "    \"\"\"\n",
    "    date_obj = datetime.strptime(date_str, date_format)\n",
    "    new_date = date_obj + timedelta(hours=hours)\n",
    "    return new_date.strftime(date_format)\n",
    "\n",
    "# Example usage\n",
    "print(add_hours(\"2014-01-01 00:0:00\", 1))\n",
    "print(add_hours(\"2014-01-01 00:0:00\", 100))\n",
    "print(add_hours(\"2014-01-01 00:0:00\", 5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.load('results/predictions/vunet/sparse_real_random_time_gaussian_full_0_predictions.npz')\n",
    "\n",
    "print(list(res.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_extra_metrics(files: list[str], model_type: str) -> None:\n",
    "    for file in files:\n",
    "        # Load existing arrays into a dictionary\n",
    "        with np.load(file) as res:\n",
    "            data = {k: res[k] for k in res.keys()}\n",
    "\n",
    "        preds = torch.from_numpy(data['predictions'])\n",
    "        targets = torch.from_numpy(data['ground_truth'])\n",
    "        errors = data['errors']\n",
    "\n",
    "        dataset, _ = load_real_data(model_type=model_type, sensor_type=\"real-random\", timesteps=8, val_set=False)\n",
    "        mask = torch.stack([target_mask for _, _, target_mask in dataset], dim=0)\n",
    "\n",
    "        unscaled_l2_relative_errors = compute_relative_error(targets * mask, preds * mask)\n",
    "        rmse, mfb, mfe = compute_extra_metrics(preds * mask, targets * mask, mask)\n",
    "\n",
    "        unscaled_error = np.mean(unscaled_l2_relative_errors)\n",
    "\n",
    "        print(\"RMSE:\", round(rmse, 3))\n",
    "        print(\"Mean Fractional Error:\", round(mfe, 3))\n",
    "        print(\"Mean Fractional Bias:\", round(mfb, 3))\n",
    "        print(\"Unscaled L2 Relative Error:\", round(unscaled_error, 3))\n",
    "        print(\"Scaled Error:\", round(np.mean(errors), 3))\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        # Add new keys\n",
    "        data.update({\n",
    "            \"rmse\": float(rmse),\n",
    "            \"mfe\": float(mfe),\n",
    "            \"mfb\": float(mfb),\n",
    "            \"unscaled_errors\": unscaled_l2_relative_errors\n",
    "        })\n",
    "\n",
    "        # Save everything back\n",
    "        np.savez_compressed(file, **data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_extra_metrics([\n",
    "    'results/predictions/vunet/random_random_5_predictions.npz',\n",
    "    'results/predictions/vunet/random_random_10_predictions.npz',\n",
    "    'results/predictions/vunet/random_random_15_predictions.npz',\n",
    "    'results/predictions/vunet/random_random_20_predictions.npz',\n",
    "    'results/predictions/vunet/random_random_25_predictions.npz',\n",
    "    'results/predictions/vunet/random_random_30_predictions.npz',\n",
    "], model_type='vunet')\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "add_extra_metrics([\n",
    "    'results/predictions/vitae/random_random_5_predictions.npz',\n",
    "    'results/predictions/vitae/random_random_10_predictions.npz',\n",
    "    'results/predictions/vitae/random_random_15_predictions.npz',\n",
    "    'results/predictions/vitae/random_random_20_predictions.npz',\n",
    "    'results/predictions/vitae/random_random_25_predictions.npz',\n",
    "    'results/predictions/vitae/random_random_30_predictions.npz',\n",
    "], model_type='vitae')\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# add_extra_metrics([\n",
    "#     'results/predictions/clstm/sparse_real_random_predictions.npz',\n",
    "#     'results/predictions/clstm/sparse_real_random_0_predictions.npz',\n",
    "#     'results/predictions/clstm/sparse_real_random_100_predictions.npz',\n",
    "\n",
    "#     'results/predictions/clstm/sparse_real_random_gaussian_full_predictions.npz',\n",
    "#     'results/predictions/clstm/sparse_real_random_gaussian_full_0_predictions.npz',\n",
    "#     'results/predictions/clstm/sparse_real_random_gaussian_full_100_predictions.npz',\n",
    "\n",
    "#     'results/predictions/clstm/sparse_real_random_time_gaussian_full_predictions.npz',\n",
    "#     'results/predictions/clstm/sparse_real_random_time_gaussian_full_0_predictions.npz',\n",
    "#     'results/predictions/clstm/sparse_real_random_time_gaussian_full_100_predictions.npz',\n",
    "\n",
    "#     'results/predictions/clstm/sparse_real_random_perlin_full_predictions.npz',\n",
    "#     'results/predictions/clstm/sparse_real_random_perlin_full_0_predictions.npz',\n",
    "#     'results/predictions/clstm/sparse_real_random_perlin_full_100_predictions.npz',\n",
    "\n",
    "#     'results/predictions/clstm/sparse_real_random_correlated_full_predictions.npz',\n",
    "#     'results/predictions/clstm/sparse_real_random_correlated_full_0_predictions.npz',\n",
    "#     'results/predictions/clstm/sparse_real_random_correlated_full_100_predictions.npz',\n",
    "# ], model_type='clstm')\n",
    "\n",
    "add_extra_metrics([\n",
    "    'results/predictions/vcnn/random_random_5_predictions.npz',\n",
    "    'results/predictions/vcnn/random_random_10_predictions.npz',\n",
    "    'results/predictions/vcnn/random_random_15_predictions.npz',\n",
    "    'results/predictions/vcnn/random_random_20_predictions.npz',\n",
    "    'results/predictions/vcnn/random_random_25_predictions.npz',\n",
    "    'results/predictions/vcnn/random_random_30_predictions.npz',\n",
    "], model_type=\"vcnn\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "add_extra_metrics([\n",
    "    'results/predictions/kriging/random_random_5_predictions.npz',\n",
    "    'results/predictions/kriging/random_random_10_predictions.npz',\n",
    "    'results/predictions/kriging/random_random_15_predictions.npz',\n",
    "    'results/predictions/kriging/random_random_20_predictions.npz',\n",
    "    'results/predictions/kriging/random_random_25_predictions.npz',\n",
    "    'results/predictions/kriging/random_random_30_predictions.npz',\n",
    "], model_type='vitae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_table_string(files: list[list[str]]) -> None:\n",
    "    line_mre  = \"& L2 MRE \"\n",
    "    line_ssim = \"& SSIM \"\n",
    "    line_rmse = \"& RMSE \"\n",
    "    line_mfe  = \"& MFE \"\n",
    "    line_mfb  = \"& MFB \"\n",
    "\n",
    "    def to_scalar(x):\n",
    "        arr = np.asarray(x)\n",
    "        return float(arr) if arr.shape == () else float(np.mean(arr))\n",
    "\n",
    "    for noise_batch_files in files:\n",
    "        mre_vals, ssim_vals, rmse_vals, mfe_vals, mfb_vals = [], [], [], [], []\n",
    "\n",
    "        for seed_file in noise_batch_files:\n",
    "            res = np.load(seed_file)\n",
    "\n",
    "            mre_val  = round(to_scalar(res[\"errors\"]), 3)\n",
    "            ssim_val = round(to_scalar(res[\"ssim\"]),    3)\n",
    "            rmse_val = round(to_scalar(res[\"rmse\"]),   3)\n",
    "            mfe_val  = round(to_scalar(res[\"mfe\"]),    3)\n",
    "            mfb_val  = round(to_scalar(res[\"mfb\"]),    3)\n",
    "\n",
    "            mre_vals.append(mre_val)\n",
    "            ssim_vals.append(ssim_val)\n",
    "            rmse_vals.append(rmse_val)\n",
    "            mfe_vals.append(mfe_val)\n",
    "            mfb_vals.append(mfb_val)\n",
    "        \n",
    "        line_mre  += f\"& {np.mean(mre_vals):.3f} \"\n",
    "        line_ssim += f\"& {np.mean(ssim_vals):.3f} \"\n",
    "        line_rmse += f\"& {np.mean(rmse_vals):.3f} \"\n",
    "        line_mfe  += f\"& {np.mean(mfe_vals):.3f} \"\n",
    "        line_mfb  += f\"& {np.mean(mfb_vals):.3f} \"\n",
    "\n",
    "    # end each row\n",
    "    line_mre  += \"\\\\\\\\\"\n",
    "    line_ssim += \"\\\\\\\\\"\n",
    "    line_rmse += \"\\\\\\\\\"\n",
    "    line_mfe  += \"\\\\\\\\\"\n",
    "    line_mfb  += \"\\\\\\\\\"\n",
    "\n",
    "    result = \"\\n\".join([line_mre, line_ssim, line_rmse, line_mfe, line_mfb])\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_table_string([\n",
    "    ['results/predictions/vcnn/random_random_5_predictions.npz'],\n",
    "    ['results/predictions/vcnn/random_random_10_predictions.npz'],\n",
    "    ['results/predictions/vcnn/random_random_15_predictions.npz'],\n",
    "    ['results/predictions/vcnn/random_random_20_predictions.npz'],\n",
    "    ['results/predictions/vcnn/random_random_25_predictions.npz'],\n",
    "    ['results/predictions/vcnn/random_random_30_predictions.npz'],\n",
    "])\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "to_table_string([\n",
    "    ['results/predictions/vunet/random_random_5_predictions.npz'],\n",
    "    ['results/predictions/vunet/random_random_10_predictions.npz'],\n",
    "    ['results/predictions/vunet/random_random_15_predictions.npz'],\n",
    "    ['results/predictions/vunet/random_random_20_predictions.npz'],\n",
    "    ['results/predictions/vunet/random_random_25_predictions.npz'],\n",
    "    ['results/predictions/vunet/random_random_30_predictions.npz'],\n",
    "])\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "to_table_string([\n",
    "    ['results/predictions/vitae/random_random_5_predictions.npz'],\n",
    "    ['results/predictions/vitae/random_random_10_predictions.npz'],\n",
    "    ['results/predictions/vitae/random_random_15_predictions.npz'],\n",
    "    ['results/predictions/vitae/random_random_20_predictions.npz'],\n",
    "    ['results/predictions/vitae/random_random_25_predictions.npz'],\n",
    "    ['results/predictions/vitae/random_random_30_predictions.npz'],\n",
    "])\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "to_table_string([\n",
    "    ['results/predictions/kriging/random_random_5_predictions.npz'],\n",
    "    ['results/predictions/kriging/random_random_10_predictions.npz'],\n",
    "    ['results/predictions/kriging/random_random_15_predictions.npz'],\n",
    "    ['results/predictions/kriging/random_random_20_predictions.npz'],\n",
    "    ['results/predictions/kriging/random_random_25_predictions.npz'],\n",
    "    ['results/predictions/kriging/random_random_30_predictions.npz'],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_polair_o3 = np.load('data/d_polair_O3.npy')\n",
    "d_polair_pm10 = np.load('data/d_polair_PM10.npy')\n",
    "d_polair_pm25 = np.load('data/d_polair_PM25.npy')\n",
    "d_polair_no2 = np.load('data/d_polair_NO2.npy')\n",
    "\n",
    "all_pollutants = np.concatenate([\n",
    "    d_polair_o3,\n",
    "    d_polair_pm10,\n",
    "    d_polair_pm25,\n",
    "    d_polair_no2\n",
    "], axis=1)\n",
    "\n",
    "noise_types = ['gaussian', 'perlin', 'time_gaussian', 'correlated']\n",
    "\n",
    "for noise_type in noise_types:\n",
    "    noise = get_noise(\n",
    "            target_shape=(1000, 4, 75, 110),\n",
    "            noise_type=noise_type,\n",
    "            device='cpu'\n",
    "        ).cpu()\n",
    "    \n",
    "    # Standardize the generated noise\n",
    "    noise_mean = noise.mean(dim=(0, 2, 3), keepdim=True)\n",
    "    noise_std = noise.std(dim=(0, 2, 3), keepdim=True)\n",
    "    noise = (noise - noise_mean) / noise_std\n",
    "    noise = noise * 5  # Scale to have std of 5\n",
    "    noise = noise.numpy()\n",
    "\n",
    "    v_max_clean = all_pollutants[0].max()\n",
    "\n",
    "    for p_idx, pollutant in enumerate(['O3', 'PM10', 'PM2.5', 'NO2']):\n",
    "        os.makedirs(f'report_images/methodology/noise/{noise_type}', exist_ok=True)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(4, 5))\n",
    "\n",
    "        im = ax.imshow(all_pollutants[0][p_idx], vmin=0, vmax=v_max_clean, cmap='viridis')\n",
    "\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Create a colorbar the same height as the image, aligned to the right\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        cbar = fig.colorbar(im, cax=cax)\n",
    "        cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'report_images/methodology/noise/{noise_type}/clean_{pollutant}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(4, 5))\n",
    "\n",
    "        im = ax.imshow(noise[0][p_idx], vmin=-10, vmax=10, cmap='viridis')\n",
    "\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Create a colorbar the same height as the image, aligned to the right\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        cbar = fig.colorbar(im, cax=cax)\n",
    "        cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'report_images/methodology/noise/{noise_type}/noise_{pollutant}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(4, 5))\n",
    "\n",
    "        im = ax.imshow(all_pollutants[0][p_idx] + noise[0][p_idx], vmin=0, vmax=v_max_clean + 5, cmap='viridis')\n",
    "\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Create a colorbar the same height as the image, aligned to the right\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        cbar = fig.colorbar(im, cax=cax)\n",
    "        cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'report_images/methodology/noise/{noise_type}/noised_{pollutant}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
